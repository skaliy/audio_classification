{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import librosa \n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = %pwd\n",
    "path = Path(f'{path}/../../data/audio_pil_og_flue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['blink','kork','skive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(path):\n",
    "    return os.path.basename(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melspectogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two methods are from the tutorial <i>Audio Classification using DeepLearning for Image Classification</i>: https://dzlab.github.io/jekyll/update/2018/11/13/audio-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(audio_fname, image_fname):\n",
    "    y, sr = librosa.load(audio_fname, sr=None)\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "    fig1 = plt.gcf()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    fig1.savefig(image_fname, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(audio_dir_path, image_dir_path=None):\n",
    "    for audio_path in audio_dir_path.ls():\n",
    "        audio_filename = get_filename(audio_path)\n",
    "        image_fname = audio_filename.split('.')[0] + '.png'\n",
    "        if not image_dir_path.exists():\n",
    "            os.mkdir(image_dir_path)\n",
    "        \n",
    "        image_fname = image_dir_path.as_posix() + '/' + image_fname\n",
    "        if Path(image_fname).exists(): continue\n",
    "        try:\n",
    "            save_spectrogram(audio_path.as_posix(), image_fname)\n",
    "        except ValueError as verr:\n",
    "            print('Failed to process %s %s' % (image_fname, verr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_melspectogram  = path/'train_melspectogram'\n",
    "if not train_path_melspectogram.exists(): \n",
    "    os.mkdir(train_path_melspectogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes: \n",
    "    audio_path = path/f'audio_files/{c}/'\n",
    "    save_path_melspectogram = path/f'train_melspectogram/{c}'\n",
    "    audio_to_spectrogram(audio_path, save_path_melspectogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw\n",
    "https://github.com/CVxTz/audio_classification/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 16000*2\n",
    "\n",
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+0.0001)\n",
    "    return data-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(file_path, input_length=input_length):\n",
    "    data = librosa.core.load(file_path, sr=16000)[0] #, sr=16000\n",
    "    if len(data)>input_length:    \n",
    "        max_offset = len(data)-input_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = data[offset:(input_length+offset)]\n",
    "    else:\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")     \n",
    "    data = audio_norm(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO renere kode med partial\n",
    "x,y,filename = [],[],[]\n",
    "\n",
    "for c in classes: \n",
    "    audio_path = path/f'audio_files/{c}/'    \n",
    "    for file_path in audio_path.ls():\n",
    "        data = load_audio_file(file_path)\n",
    "        x.append(data)\n",
    "        y.append(c)\n",
    "        filename.append(get_filename(file_path).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x)\n",
    "df['filename'], df['classes'] = filename, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = %pwd\n",
    "save_path = Path(f'{save_path}/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(save_path/'raw.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_base = load_audio_file(audio_path.ls()[4])\n",
    "#fig = plt.figure(figsize=(14, 8))\n",
    "#plt.plotqwq(np.linspace(0, 1, input_length), data_base)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, sample_rate = librosa.load(audio_path.ls()[4], sr=None)\n",
    "#plt.figure(figsize=(12, 4))\n",
    "#librosa.display.waveplot(data, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random selection of validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "blink, kork, skive = random.sample(range(0, 29), 9), random.sample(range(30, 59), 9), random.sample(range(60, 89), 9)\n",
    "idx = blink + kork + skive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df['filename'].iloc[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.to_csv(save_path/'validation.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use move_spectogram notebook to create a validation folder and move the images (ImageNet-style). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
